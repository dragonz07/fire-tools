{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#!pip install https://sparkflows-release.s3.amazonaws.com/fire/jupyter-docker/firenotebookwheel/fire_notebook-3.1.0-py3-none-any.whl"
      ],
      "metadata": {
        "id": "3jeFut4c9ml6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b1b0d84-f823-4887-847d-2068b6cdc323"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fire-notebook==3.1.0\n",
            "  Using cached https://sparkflows-release.s3.amazonaws.com/fire/jupyter-docker/firenotebookwheel/fire_notebook-3.1.0-py3-none-any.whl (1.3 MB)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install pyspark\n",
        "#import pyspark"
      ],
      "metadata": {
        "id": "Fah-M68K-73i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PQhEgY2iu7Js"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import sys\n",
        "from fire_notebook.output.workflowcontext import RestWorkflowContext\n",
        "\n",
        "parameters_list = sys.argv\n",
        "#print(len(sys.argv), \"parameters_list\")\n",
        "'''\n",
        "if len(sys.argv) >= 3:\n",
        "    #restworkflowcontext = RestWorkflowContext(parameters=parameters_list)\n",
        "    FILE_PATH = \"churn.all\" #Analytical Docker App\n",
        "\n",
        "else:\n",
        "    FILE_PATH = \"/content/drive/MyDrive/data/churn.all\" #google coollab\n",
        "\n",
        "    #restworkflowcontext = RestWorkflowContext(debug=False)\n",
        "'''\n",
        "restworkflowcontext = RestWorkflowContext(parameters=parameters_list)\n",
        "\n",
        "\n",
        "message=\"20\"\n",
        "restworkflowcontext.outputProgress(9, title=\"Progress\", progress=message)\n",
        "\n",
        "# IMPORTANT CHANGE PATH WHEN PUSHING TO DOCKERS\n",
        "#FILE_PATH = \"/content/drive/MyDrive/data/churn.all\" #google coollab\n",
        "FILE_PATH = \"churn.all\" #Analytical Docker App\n",
        "\n",
        "# Read the CSV file, treating empty strings as NaN and forcing 'churned' to be read as a string\n",
        "df = pd.read_csv(FILE_PATH, na_values=[''], keep_default_na=False, dtype={'churned': str})\n",
        "\n",
        "\n",
        "\n",
        "# Define a function to filter the DataFrame based on user-specified criteria\n",
        "def filter_dataframe(df, state_filter, intl_plan_filter, voice_mail_filter):\n",
        "    # Create a copy of the DataFrame to avoid modifying the original\n",
        "    filtered_df = df.copy()\n",
        "\n",
        "    # Filter by state if a specific state is provided\n",
        "    if state_filter != '%':\n",
        "        filtered_df = filtered_df[filtered_df['state'] == state_filter]\n",
        "\n",
        "    # Filter by international plan if a specific plan is provided\n",
        "    if intl_plan_filter != '%':\n",
        "        filtered_df = filtered_df[filtered_df['intl_plan'] == intl_plan_filter]\n",
        "\n",
        "    # Filter by voice mail plan if a specific plan is provided\n",
        "    if voice_mail_filter != '%':\n",
        "        filtered_df = filtered_df[filtered_df['voice_mail_plan'] == voice_mail_filter]\n",
        "\n",
        "    # Return the filtered DataFrame\n",
        "    return filtered_df\n",
        "\n",
        "# Define the filter criteria (these would typically come from user input in a web application)\n",
        "state_filter = restworkflowcontext.getParmeters(parameter_name=\"arg_state\", default='%')\n",
        "intl_plan_filter = restworkflowcontext.getParmeters(parameter_name=\"arg_intl_plan\", default='%')\n",
        "voice_mail_filter = restworkflowcontext.getParmeters(parameter_name=\"arg_voice_mail_plan\", default='%')\n",
        "#churned_filter = restworkflowcontext.getParmeters(parameter_name=\"arg_churned\", default='%')\n",
        "\n",
        "'''\n",
        "state_filter = \"%\"  # Select all states\n",
        "intl_plan_filter = \"%\"  # Select all international plans\n",
        "voice_mail_filter = \"%\"  # Select all voicemail plans\n",
        "'''\n",
        "\n",
        "# Call the filter function with the specified criteria\n",
        "filtered_df = filter_dataframe(df, state_filter, intl_plan_filter, voice_mail_filter)\n",
        "\n",
        "# Define a list of columns for which summary statistics will be computed\n",
        "summary_cols = [\n",
        "    # List of columns to include in the summary statistics\n",
        "    \"total_day_minutes\", \"total_day_calls\", \"total_day_charge\", \"total_eve_calls\",\n",
        "    \"number_vmail_messages\", \"total_eve_minutes\", \"total_eve_charge\",\n",
        "    \"total_night_minutes\", \"total_night_calls\", \"total_night_charge\",\n",
        "    \"total_intl_minutes\", \"total_intl_calls\", \"total_intl_charge\",\n",
        "    \"number_customer_service_calls\"\n",
        "]\n",
        "\n",
        "# Compute summary statistics for the filtered DataFrame\n",
        "summary_df = filtered_df[summary_cols].agg(['count', 'mean', 'min', 'max', 'std', 'var']).round(3)\n",
        "\n",
        "# Print the summary statistics\n",
        "print(\"Summary Statistics for Filtered Data:\\n\", summary_df)\n",
        "\n",
        "restworkflowcontext.outPandasDataframe(9, \"Summary Statistics for Filtered Data\", summary_df)\n",
        "\n",
        "# Drop rows with null values from the filtered DataFrame\n",
        "df_drop_null = filtered_df.dropna()\n",
        "\n",
        "# Select numeric and boolean columns for the correlation matrix calculation\n",
        "numeric_bool_cols = df_drop_null.select_dtypes(include=['number', 'bool']).columns\n",
        "\n",
        "# Calculate the correlation matrix for the numeric and boolean columns\n",
        "corr_matrix = df_drop_null[numeric_bool_cols].corr()\n",
        "\n",
        "# Print the correlation matrix\n",
        "print(\"\\nCorrelation Matrix:\\n\", corr_matrix)\n",
        "restworkflowcontext.outPandasDataframe(9, \"Correlation Matrix Table\", corr_matrix)\n",
        "\n",
        "\n",
        "# Visualize the correlation matrix using a heatmap\n",
        "plt.figure(figsize=(8, 8))\n",
        "sns.heatmap(corr_matrix, annot=False, cmap='coolwarm', vmin=-1, vmax=1, center=0)\n",
        "plt.title('Correlation Matrix')\n",
        "plt.show()\n",
        "\n",
        "# Group the filtered DataFrame by 'churned' and compute aggregated statistics\n",
        "groupby_df = filtered_df.groupby('churned').agg({\n",
        "    'total_day_charge': 'sum',\n",
        "    'total_eve_charge': 'sum',\n",
        "    'total_night_charge': 'sum',\n",
        "    'total_intl_charge': 'sum'\n",
        "}).reset_index()\n",
        "\n",
        "# Print the grouped data\n",
        "print(\"\\nGrouped by churned:\\n\", groupby_df.head())\n",
        "restworkflowcontext.outPandasDataframe(9, \"Churned Statistics\", groupby_df.head())\n",
        "\n",
        "\n",
        "# Create a pie chart to visualize the distribution of churned and non-churned customers\n",
        "churn_counts = filtered_df['churned'].value_counts()\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.pie(churn_counts.values, labels=churn_counts.index, autopct='%1.1f%%', startangle=90)\n",
        "plt.title('Churn Distribution')\n",
        "plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle\n",
        "plt.show()\n",
        "\n",
        "# Create a box plot to visualize the distribution of customer service calls by churn status\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.boxplot(x='churned', y='number_customer_service_calls', data=filtered_df)\n",
        "plt.title('Number of Customer Service Calls by Churn Status')\n",
        "plt.show()\n",
        "\n",
        "# Create a count plot to visualize the distribution of international plan subscriptions by churn status\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.countplot(x='intl_plan', hue='churned', data=filtered_df)\n",
        "plt.title('International Plan Subscription by Churn Status')\n",
        "plt.show()\n",
        "\n",
        "progress_percentage = \"100\"\n",
        "restworkflowcontext.outputProgress(id=9, title=\"Progress\", progress=progress_percentage)\n",
        "\n",
        "message = \"Success.\"\n",
        "restworkflowcontext.outSuccess(9, title=\"Success\", text=message)"
      ]
    }
  ]
}